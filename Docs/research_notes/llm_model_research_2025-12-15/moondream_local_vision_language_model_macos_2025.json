{
  "query": "Moondream local vision language model macOS 2025",
  "answer": "Do you want the quickest way to run Moondream locally on a Mac? Here are the two good options for macOS (Apple Silicon) as of December 16, 2025:\n\nFastest (no setup): Moondream Station\n- Install: pip install moondream-station\n- Run the local server: moondream-station (defaults to http://localhost:2020; it will pick another free port if needed).\n- Use it from code:\n  - Python: connect with moondream.vl(endpoint=\"http://localhost:2020/v1\") and call model.query / caption / detect / point on PIL images.\n- Useful CLI: models (list), models switch <model>, start [port], stop, settings set logging false (turns off anonymous metrics). ([docs.moondream.ai](https://docs.moondream.ai/station/))\n- Station is free and available via PyPI for Mac, Windows, and Linux. ([moondream.ai](https://moondream.ai/station?utm_source=openai))\n\nMore control (programmatic, no server): Hugging Face + PyTorch (runs on Apple’s MPS)\n- pip install torch transformers pillow\n- Python (pin a known-good release):\n  - from transformers import AutoModelForCausalLM\n  - model = AutoModelForCausalLM.from_pretrained(\"vikhyatk/moondream2\", revision=\"2025-06-21\", trust_remote_code=True, device_map={\"\": \"mps\"})\n  - Then use model.caption(image, …), model.query(image, …), model.detect(image, …), model.point(image, …). ([huggingface.co](https://huggingface.co/vikhyatk/moondream2))\n\nNotes you should know\n- Default Station port is 2020; the API is reachable at /v1 and works with their Python and Node clients or plain HTTP. You can manage models and settings entirely from the Station CLI. ([docs.moondream.ai](https://docs.moondream.ai/station/))\n- Latest Moondream 2 model card (June 21, 2025) includes Apple Silicon guidance (device_map \"mps\") and the higher-level caption/query/detect/point helpers. ([huggingface.co](https://huggingface.co/vikhyatk/moondream2))\n- 4-bit quantized builds: officially available in Station on Linux; Mac support was “coming soon” per Moondream’s May 21, 2025 update and Station 2 post (Sept 23, 2025). If you need 4-bit on macOS specifically, check their latest Station release notes before relying on it. ([moondream.ai](https://moondream.ai/blog/smaller-faster-moondream-with-qat))\n\nIf you tell me your Mac model (e.g., M1/M2/M3 and RAM), I can suggest the best model variant and settings for speed vs. accuracy.",
  "citations": [],
  "sources": [],
  "metadata": {}
}
